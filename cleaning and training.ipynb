{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CLEANING OF DATA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaibram/Research/blob/main/cleaning%20and%20training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z22fpRm9rqlO"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib\r\n",
        "matplotlib.use('Agg')\r\n",
        "from sklearn.preprocessing import LabelBinarizer # Label encoding, 1-hot encoding, multi-encoding\r\n",
        "# LABEL binarizer is a 1-hot encoded MATRIX \r\n",
        "import cv2\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import random\r\n",
        "import imutils\r\n",
        "from imutils import paths\r\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHCixC-TUt99",
        "outputId": "10c406f7-2acd-4de7-f2ae-2ee271c32080"
      },
      "source": [
        "covid = '/content/SAMPLE'\r\n",
        "def loadImages(path = \"/content/SAMPLE\"):\r\n",
        "    temp = os.listdir(path)\r\n",
        "    images=[]\r\n",
        "    for i in temp:\r\n",
        "      if(i.endswith(\"jpg,png\")):\r\n",
        "        images.append(i)\r\n",
        "    print(temp)\r\n",
        "\r\n",
        "all_images = sorted(list(paths.list_images(covid)))\r\n",
        "all_images[:100000]\r\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/SAMPLE/COVID 001.jpg',\n",
              " '/content/SAMPLE/COVID 002.jpg',\n",
              " '/content/SAMPLE/COVID 003.jpg',\n",
              " '/content/SAMPLE/COVID 004.jpg',\n",
              " '/content/SAMPLE/COVID 005.jpg',\n",
              " '/content/SAMPLE/COVID 006.jpg',\n",
              " '/content/SAMPLE/COVID 007.jpg',\n",
              " '/content/SAMPLE/COVID 008.jpg',\n",
              " '/content/SAMPLE/COVID 009.jpg',\n",
              " '/content/SAMPLE/COVID 010.jpg',\n",
              " '/content/SAMPLE/COVID 011.jpg',\n",
              " '/content/SAMPLE/COVID 012.jpg',\n",
              " '/content/SAMPLE/COVID 013.jpg',\n",
              " '/content/SAMPLE/COVID 014.jpg',\n",
              " '/content/SAMPLE/COVID 015.jpg',\n",
              " '/content/SAMPLE/COVID 016.jpg',\n",
              " '/content/SAMPLE/COVID 017.jpg',\n",
              " '/content/SAMPLE/COVID 018.jpg',\n",
              " '/content/SAMPLE/COVID 019.jpg',\n",
              " '/content/SAMPLE/COVID 020.jpg',\n",
              " '/content/SAMPLE/COVID 021.jpg',\n",
              " '/content/SAMPLE/COVID 022.jpg',\n",
              " '/content/SAMPLE/COVID 023.jpg',\n",
              " '/content/SAMPLE/COVID 024.jpg',\n",
              " '/content/SAMPLE/COVID 025.jpg',\n",
              " '/content/SAMPLE/COVID 026.jpg',\n",
              " '/content/SAMPLE/COVID 027.jpg',\n",
              " '/content/SAMPLE/COVID 028.jpg',\n",
              " '/content/SAMPLE/COVID 029.jpg',\n",
              " '/content/SAMPLE/COVID 030.jpg',\n",
              " '/content/SAMPLE/COVID 031.jpg',\n",
              " '/content/SAMPLE/COVID 032.jpg',\n",
              " '/content/SAMPLE/COVID 033.jpg',\n",
              " '/content/SAMPLE/COVID 034.jpg',\n",
              " '/content/SAMPLE/COVID 035.jpg',\n",
              " '/content/SAMPLE/COVID 036.jpg',\n",
              " '/content/SAMPLE/COVID 037.jpg',\n",
              " '/content/SAMPLE/COVID 038.jpg',\n",
              " '/content/SAMPLE/COVID 039.jpg',\n",
              " '/content/SAMPLE/COVID 040.jpg',\n",
              " '/content/SAMPLE/COVID 041.jpg',\n",
              " '/content/SAMPLE/COVID 042.jpg',\n",
              " '/content/SAMPLE/COVID 043.jpg',\n",
              " '/content/SAMPLE/COVID 044.jpg',\n",
              " '/content/SAMPLE/COVID 045.jpg',\n",
              " '/content/SAMPLE/COVID 046.jpg',\n",
              " '/content/SAMPLE/COVID 047.jpg',\n",
              " '/content/SAMPLE/COVID 048.jpg',\n",
              " '/content/SAMPLE/COVID 049.jpg',\n",
              " '/content/SAMPLE/COVID 050.jpg',\n",
              " '/content/SAMPLE/COVID 113.jpg',\n",
              " '/content/SAMPLE/COVID 114.jpg',\n",
              " '/content/SAMPLE/COVID 115.jpg',\n",
              " '/content/SAMPLE/COVID 118.jpg',\n",
              " '/content/SAMPLE/COVID 119.jpg',\n",
              " '/content/SAMPLE/COVID 120.jpg',\n",
              " '/content/SAMPLE/COVID 123.jpg',\n",
              " '/content/SAMPLE/COVID 124.jpg',\n",
              " '/content/SAMPLE/COVID 125.jpg',\n",
              " '/content/SAMPLE/COVID 128.jpg',\n",
              " '/content/SAMPLE/COVID 129.jpg',\n",
              " '/content/SAMPLE/COVID 130.jpg',\n",
              " '/content/SAMPLE/COVID 133.jpg',\n",
              " '/content/SAMPLE/COVID 134.jpg',\n",
              " '/content/SAMPLE/COVID 135.jpg',\n",
              " '/content/SAMPLE/COVID 138.jpg',\n",
              " '/content/SAMPLE/COVID 139.jpg',\n",
              " '/content/SAMPLE/COVID 140.jpg',\n",
              " '/content/SAMPLE/COVID 143.jpg',\n",
              " '/content/SAMPLE/COVID 144.jpg',\n",
              " '/content/SAMPLE/COVID 145.jpg',\n",
              " '/content/SAMPLE/COVID 148.jpg',\n",
              " '/content/SAMPLE/COVID 149.jpg',\n",
              " '/content/SAMPLE/COVID 150.jpg',\n",
              " '/content/SAMPLE/COVID 153.jpg',\n",
              " '/content/SAMPLE/COVID 154.jpg',\n",
              " '/content/SAMPLE/COVID 155.jpg',\n",
              " '/content/SAMPLE/COVID 158.jpg',\n",
              " '/content/SAMPLE/COVID 159.jpg',\n",
              " '/content/SAMPLE/COVID 160.jpg',\n",
              " '/content/SAMPLE/COVID 163.jpg',\n",
              " '/content/SAMPLE/COVID 164.jpg',\n",
              " '/content/SAMPLE/COVID 165.jpg',\n",
              " '/content/SAMPLE/COVID 168.jpg',\n",
              " '/content/SAMPLE/COVID 169.jpg',\n",
              " '/content/SAMPLE/COVID 170.jpg',\n",
              " '/content/SAMPLE/COVID 173.jpg',\n",
              " '/content/SAMPLE/COVID 174.jpg',\n",
              " '/content/SAMPLE/COVID 175.jpg',\n",
              " '/content/SAMPLE/COVID 178.jpg',\n",
              " '/content/SAMPLE/COVID 179.jpg',\n",
              " '/content/SAMPLE/COVID 180.jpg',\n",
              " '/content/SAMPLE/COVID 183.jpg',\n",
              " '/content/SAMPLE/COVID 184.jpg',\n",
              " '/content/SAMPLE/COVID 185.jpg',\n",
              " '/content/SAMPLE/COVID 188.jpg',\n",
              " '/content/SAMPLE/COVID 189.jpg',\n",
              " '/content/SAMPLE/COVID 190.jpg',\n",
              " '/content/SAMPLE/COVID 193.jpg',\n",
              " '/content/SAMPLE/COVID 194.jpg',\n",
              " '/content/SAMPLE/COVID 195.jpg',\n",
              " '/content/SAMPLE/COVID 198.jpg',\n",
              " '/content/SAMPLE/COVID 199.jpg',\n",
              " '/content/SAMPLE/COVID 200.jpg',\n",
              " '/content/SAMPLE/COVID 203.jpg',\n",
              " '/content/SAMPLE/COVID 204.jpg',\n",
              " '/content/SAMPLE/COVID 205.jpg',\n",
              " '/content/SAMPLE/COVID 208.jpg',\n",
              " '/content/SAMPLE/COVID 209.jpg',\n",
              " '/content/SAMPLE/COVID 210.jpg',\n",
              " '/content/SAMPLE/COVID 213.jpg',\n",
              " '/content/SAMPLE/COVID 215.jpg',\n",
              " '/content/SAMPLE/NORMAL 001.jpg',\n",
              " '/content/SAMPLE/NORMAL 002.jpg',\n",
              " '/content/SAMPLE/NORMAL 003.jpg',\n",
              " '/content/SAMPLE/NORMAL 004.jpg',\n",
              " '/content/SAMPLE/NORMAL 005.jpg',\n",
              " '/content/SAMPLE/NORMAL 006.jpg',\n",
              " '/content/SAMPLE/NORMAL 007.jpg',\n",
              " '/content/SAMPLE/NORMAL 008.jpg',\n",
              " '/content/SAMPLE/NORMAL 009.jpg',\n",
              " '/content/SAMPLE/NORMAL 010.jpg',\n",
              " '/content/SAMPLE/NORMAL 011.jpg',\n",
              " '/content/SAMPLE/NORMAL 012.jpg',\n",
              " '/content/SAMPLE/NORMAL 013.jpg',\n",
              " '/content/SAMPLE/NORMAL 014.jpg',\n",
              " '/content/SAMPLE/NORMAL 015.jpg',\n",
              " '/content/SAMPLE/NORMAL 016.jpg',\n",
              " '/content/SAMPLE/NORMAL 017.jpg',\n",
              " '/content/SAMPLE/NORMAL 018.jpg',\n",
              " '/content/SAMPLE/NORMAL 019.jpg',\n",
              " '/content/SAMPLE/NORMAL 020.jpg',\n",
              " '/content/SAMPLE/NORMAL 021.jpg',\n",
              " '/content/SAMPLE/NORMAL 022.jpg',\n",
              " '/content/SAMPLE/NORMAL 023.jpg',\n",
              " '/content/SAMPLE/NORMAL 024.jpg',\n",
              " '/content/SAMPLE/NORMAL 025.jpg',\n",
              " '/content/SAMPLE/NORMAL 026.jpg',\n",
              " '/content/SAMPLE/NORMAL 027.jpg',\n",
              " '/content/SAMPLE/NORMAL 028.jpg',\n",
              " '/content/SAMPLE/NORMAL 029.jpg',\n",
              " '/content/SAMPLE/NORMAL 030.jpg',\n",
              " '/content/SAMPLE/NORMAL 031.jpg',\n",
              " '/content/SAMPLE/NORMAL 032.jpg',\n",
              " '/content/SAMPLE/NORMAL 033.jpg',\n",
              " '/content/SAMPLE/NORMAL 034.jpg',\n",
              " '/content/SAMPLE/NORMAL 035.jpg',\n",
              " '/content/SAMPLE/NORMAL 036.jpg',\n",
              " '/content/SAMPLE/NORMAL 037.jpg',\n",
              " '/content/SAMPLE/NORMAL 038.jpg',\n",
              " '/content/SAMPLE/NORMAL 039.jpg',\n",
              " '/content/SAMPLE/NORMAL 040.jpg',\n",
              " '/content/SAMPLE/NORMAL 041.jpg',\n",
              " '/content/SAMPLE/NORMAL 042.jpg',\n",
              " '/content/SAMPLE/NORMAL 043.jpg',\n",
              " '/content/SAMPLE/NORMAL 044.jpg',\n",
              " '/content/SAMPLE/NORMAL 045.jpg',\n",
              " '/content/SAMPLE/NORMAL 047.jpg',\n",
              " '/content/SAMPLE/NORMAL 048.jpg',\n",
              " '/content/SAMPLE/NORMAL 049.jpg',\n",
              " '/content/SAMPLE/NORMAL 050.jpg',\n",
              " '/content/SAMPLE/NORMAL 163.jpg',\n",
              " '/content/SAMPLE/NORMAL 164.jpg',\n",
              " '/content/SAMPLE/NORMAL 165.jpg',\n",
              " '/content/SAMPLE/NORMAL 169.jpg',\n",
              " '/content/SAMPLE/NORMAL 170.jpg',\n",
              " '/content/SAMPLE/NORMAL 173.jpg',\n",
              " '/content/SAMPLE/NORMAL 174.jpg',\n",
              " '/content/SAMPLE/NORMAL 176.jpg',\n",
              " '/content/SAMPLE/NORMAL 177.jpg',\n",
              " '/content/SAMPLE/NORMAL 178.jpg',\n",
              " '/content/SAMPLE/NORMAL 179.jpg',\n",
              " '/content/SAMPLE/NORMAL 180.jpg',\n",
              " '/content/SAMPLE/NORMAL 181.jpg',\n",
              " '/content/SAMPLE/NORMAL 182.jpg',\n",
              " '/content/SAMPLE/NORMAL 183.jpg',\n",
              " '/content/SAMPLE/NORMAL 184.jpg',\n",
              " '/content/SAMPLE/NORMAL 185.jpg',\n",
              " '/content/SAMPLE/NORMAL 186.jpg',\n",
              " '/content/SAMPLE/NORMAL 187.jpg',\n",
              " '/content/SAMPLE/NORMAL 188.jpg',\n",
              " '/content/SAMPLE/NORMAL 189.jpg',\n",
              " '/content/SAMPLE/NORMAL 190.jpg',\n",
              " '/content/SAMPLE/NORMAL 192.jpg',\n",
              " '/content/SAMPLE/NORMAL 193.jpg',\n",
              " '/content/SAMPLE/NORMAL 194.jpg',\n",
              " '/content/SAMPLE/NORMAL 195.jpg',\n",
              " '/content/SAMPLE/NORMAL 196.jpg',\n",
              " '/content/SAMPLE/NORMAL 197.jpg',\n",
              " '/content/SAMPLE/NORMAL 198.jpg',\n",
              " '/content/SAMPLE/NORMAL 199.jpg',\n",
              " '/content/SAMPLE/NORMAL 200.jpg',\n",
              " '/content/SAMPLE/NORMAL 201.jpg',\n",
              " '/content/SAMPLE/NORMAL 202.jpg',\n",
              " '/content/SAMPLE/NORMAL 203.jpg',\n",
              " '/content/SAMPLE/NORMAL 204.jpg',\n",
              " '/content/SAMPLE/NORMAL 205.jpg',\n",
              " '/content/SAMPLE/NORMAL 209.jpg',\n",
              " '/content/SAMPLE/NORMAL 210.jpg',\n",
              " '/content/SAMPLE/NORMAL 213.jpg',\n",
              " '/content/SAMPLE/NORMAL 214.jpg',\n",
              " '/content/SAMPLE/NORMAL 215.jpg',\n",
              " '/content/SAMPLE/NORMAL 218.jpg',\n",
              " '/content/SAMPLE/NORMAL 219.jpg',\n",
              " '/content/SAMPLE/NORMAL 220.jpg',\n",
              " '/content/SAMPLE/NORMAL 223.jpg',\n",
              " '/content/SAMPLE/NORMAL 224.jpg',\n",
              " '/content/SAMPLE/NORMAL 225.jpg',\n",
              " '/content/SAMPLE/NORMAL 228.jpg',\n",
              " '/content/SAMPLE/NORMAL 229.jpg',\n",
              " '/content/SAMPLE/NORMAL 230.jpg',\n",
              " '/content/SAMPLE/NORMAL 233.jpg']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ay_n8WDbFQSw"
      },
      "source": [
        "filenames=os.listdir(\"/content/SAMPLE\")\r\n",
        "categories=[]\r\n",
        "for f_name in filenames:\r\n",
        "    category=f_name.split(' ')[0]\r\n",
        "    \r\n",
        "    if category=='NORMAL':\r\n",
        "        categories.append(1)\r\n",
        "    else:\r\n",
        "        categories.append(0)\r\n",
        "df=pd.DataFrame({\r\n",
        "    'filename':filenames,\r\n",
        "    'category':categories\r\n",
        "})"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gyxa5ADUFwpn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "6d51f6a4-e0b5-4c0a-9729-4d0ed9c3a2cf"
      },
      "source": [
        "df\r\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NORMAL 037.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>COVID 154.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>COVID 007.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NORMAL 036.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>COVID 015.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207</th>\n",
              "      <td>NORMAL 203.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>208</th>\n",
              "      <td>NORMAL 013.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>NORMAL 050.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>210</th>\n",
              "      <td>COVID 033.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211</th>\n",
              "      <td>COVID 009.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>212 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           filename  category\n",
              "0    NORMAL 037.jpg         1\n",
              "1     COVID 154.jpg         0\n",
              "2     COVID 007.jpg         0\n",
              "3    NORMAL 036.jpg         1\n",
              "4     COVID 015.jpg         0\n",
              "..              ...       ...\n",
              "207  NORMAL 203.jpg         1\n",
              "208  NORMAL 013.jpg         1\n",
              "209  NORMAL 050.jpg         1\n",
              "210   COVID 033.jpg         0\n",
              "211   COVID 009.jpg         0\n",
              "\n",
              "[212 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOdx9cXKHs40"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmJkZHNJHg5X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "a60e9ecb-1cf3-49c1-e57b-ec9339d9313c"
      },
      "source": [
        "train_df"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-ef797c2b3b5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0vXWsv9Dc3k"
      },
      "source": [
        "from keras import backend\r\n",
        "from keras.layers.core import Dense, Dropout, Flatten, Activation\r\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\r\n",
        "from keras.layers.normalization import BatchNormalization\r\n",
        "from keras.models import Sequential"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvNdsdsGMrEz"
      },
      "source": [
        "Image_Width=128\r\n",
        "Image_Height=128\r\n",
        "Image_Size=(Image_Width,Image_Height)\r\n",
        "Image_Channels=3"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7p6ISMWuIMB3"
      },
      "source": [
        "model=Sequential()\r\n",
        "model.add(Conv2D(32,(3,3),activation='relu',input_shape=(Image_Width,Image_Height,Image_Channels)))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "model.add(Dropout(0.25))\r\n",
        "model.add(Conv2D(64,(3,3),activation='relu'))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "model.add(Dropout(0.25))\r\n",
        "model.add(Conv2D(128,(3,3),activation='relu'))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "model.add(Dropout(0.25))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(512,activation='relu'))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Dense(2,activation='softmax'))\r\n",
        "model.compile(loss='categorical_crossentropy',\r\n",
        "  optimizer='rmsprop',metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhMDF1sHI_Lh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a25c8854-e1d4-4c84-bb75-b438151995f5"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 126, 126, 32)      896       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 126, 126, 32)      128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 63, 63, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 63, 63, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 61, 61, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 61, 61, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 30, 30, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 28, 28, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 28, 28, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               12845568  \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 12,942,786\n",
            "Trainable params: 12,941,314\n",
            "Non-trainable params: 1,472\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgF3VcPWI_I1"
      },
      "source": [
        "df[\"category\"] = df[\"category\"].replace({0:'COVID',1:'NORMAL'})\r\n",
        "train_df,validate_df = train_test_split(df,test_size=0.20,\r\n",
        "  random_state=42)\r\n",
        "train_df = train_df.reset_index(drop=True)\r\n",
        "validate_df = validate_df.reset_index(drop=True)\r\n",
        "total_train=train_df.shape[0]\r\n",
        "total_validate=validate_df.shape[0]\r\n",
        "batch_size=15"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYIgh005O-67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f75b1d8-f2ff-4e2e-a346-9203a704f2dd"
      },
      "source": [
        "total_validate"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBk2iYeCI_GR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aec36ccd-b8e0-4051-9b95-a7789e5ed0a5"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rotation_range=15,\r\n",
        "                                rescale=1./255,\r\n",
        "                                shear_range=0.1,\r\n",
        "                                zoom_range=0.2,\r\n",
        "                                horizontal_flip=True,\r\n",
        "                                width_shift_range=0.1,\r\n",
        "                                height_shift_range=0.1\r\n",
        "                                )\r\n",
        "train_generator = train_datagen.flow_from_dataframe(train_df,\r\n",
        "                                                 \"/content/SAMPLE\",x_col='filename',y_col='category',\r\n",
        "                                                 target_size=Image_Size,\r\n",
        "                                                 class_mode='categorical',\r\n",
        "                                                 batch_size=batch_size)\r\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\r\n",
        "validation_generator = validation_datagen.flow_from_dataframe(\r\n",
        "    validate_df, \r\n",
        "    \"/content/SAMPLE\", \r\n",
        "    x_col='filename',\r\n",
        "    y_col='category',\r\n",
        "    target_size=Image_Size,\r\n",
        "    class_mode='categorical',\r\n",
        "    batch_size=batch_size\r\n",
        ")\r\n",
        "test_datagen = ImageDataGenerator(rotation_range=15,\r\n",
        "                                rescale=1./255,\r\n",
        "                                shear_range=0.1,\r\n",
        "                                zoom_range=0.2,\r\n",
        "                                horizontal_flip=True,\r\n",
        "                                width_shift_range=0.1,\r\n",
        "                                height_shift_range=0.1)\r\n",
        "test_generator = train_datagen.flow_from_dataframe(train_df,\r\n",
        "                                                 \"/content/TEST-1\",x_col='filename',y_col='category',\r\n",
        "                                                 target_size=Image_Size,\r\n",
        "                                                 class_mode='categorical',\r\n",
        "                                                 batch_size=batch_size)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 169 validated image filenames belonging to 2 classes.\n",
            "Found 43 validated image filenames belonging to 2 classes.\n",
            "Found 49 validated image filenames belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/dataframe_iterator.py:282: UserWarning: Found 120 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
            "  .format(n_invalid, x_col)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjXaSp18I_DY"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\r\n",
        "earlystop = EarlyStopping(patience = 10)\r\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_acc',patience = 2,verbose = 1,factor = 0.5,min_lr = 0.00001)\r\n",
        "callbacks = [earlystop,learning_rate_reduction]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clS19OWxQA6h"
      },
      "source": [
        "test_filenames = os.listdir(\"/content/SAMPLE\")\r\n",
        "test_df = pd.DataFrame({\r\n",
        "    'filename': test_filenames\r\n",
        "})\r\n",
        "nb_samples = test_df.shape[0]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjXpvJaDI-_e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a147be16-1392-476e-b100-114f9b0b3fc2"
      },
      "source": [
        "epochs=10\r\n",
        "history = model.fit_generator(\r\n",
        "    train_generator, \r\n",
        "    epochs=epochs,\r\n",
        "    validation_data=validation_generator,\r\n",
        "    validation_steps=total_validate//batch_size,\r\n",
        "    steps_per_epoch=total_train//batch_size,\r\n",
        "    callbacks=callbacks\r\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "UnknownError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-f7b6d0c9c94b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_validate\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_train\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1859\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnknownError\u001b[0m:  OSError: image file is truncated (8 bytes not processed)\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 620, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 891, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\", line 807, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\", line 933, in generator_fn\n    yield x[i]\n\n  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\", line 230, in _get_batches_of_transformed_samples\n    interpolation=self.interpolation)\n\n  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\", line 125, in load_img\n    img = img.convert('RGB')\n\n  File \"/usr/local/lib/python3.7/dist-packages/PIL/Image.py\", line 873, in convert\n    self.load()\n\n  File \"/usr/local/lib/python3.7/dist-packages/PIL/ImageFile.py\", line 247, in load\n    \"(%d bytes not processed)\" % len(b)\n\nOSError: image file is truncated (8 bytes not processed)\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_1895]\n\nFunction call stack:\ntrain_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0AbUFcoQ_nu"
      },
      "source": [
        "test_filenames = os.listdir(\"/content/TEST-1\")\r\n",
        "test_df = pd.DataFrame({\r\n",
        "    'filename': test_filenames\r\n",
        "})\r\n",
        "nb_samples = test_df.shape[0]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ-NwMosOFkl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89011f19-59e5-4a0e-888a-2925218bf08f"
      },
      "source": [
        "predict = model.predict_generator(test_generator, steps=np.ceil(nb_samples/batch_size))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faZnQHzCOKZZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "8c7dffdb-653a-40ac-f277-93ef91d9ccad"
      },
      "source": [
        "test_df['category'] = np.argmax(predict, axis=-1)\r\n",
        "label_map = dict((v,k) for k,v in train_generator.class_indices.items())\r\n",
        "test_df['category'] = test_df['category'].replace(label_map)\r\n",
        "test_df['category'] = test_df['category'].replace({ 'NORMAL': 1, 'COVID': 0 })"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-a8b53dd5117f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlabel_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m \u001b[0;34m'NORMAL'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'COVID'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3042\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3043\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3044\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3046\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3118\u001b[0m         \"\"\"\n\u001b[1;32m   3119\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3120\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3121\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   3766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3767\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3768\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3769\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3770\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         raise ValueError(\n\u001b[0;32m--> 748\u001b[0;31m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0;34m\"does not match length of index \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Length of values (49) does not match length of index (60)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eh5nz5PI0cf"
      },
      "source": [
        "HP_epoch = 100\r\n",
        "HP_image_dim = (96,96,3)\r\n",
        "data = []\r\n",
        "labels = [] \r\n",
        "for impath in all_images:\r\n",
        "  img = cv2.imread(impath)\r\n",
        "  try:\r\n",
        "    img = cv2.imread(impath)\r\n",
        "    resized = cv2.resize(img, (HP_image_dim[0],HP_image_dim[1]) )\r\n",
        "  except:\r\n",
        "        break\r\n",
        "  imageData = img_to_array(resized)\r\n",
        "  data.append(imageData)\r\n",
        "  # extract label from filename (2nd last element) / \\\\ \r\n",
        "  label = impath.split(os.path.sep)[-2]\r\n",
        "  labels.append(label)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
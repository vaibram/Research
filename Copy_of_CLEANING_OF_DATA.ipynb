{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of CLEANING OF DATA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaibram/Research/blob/main/Copy_of_CLEANING_OF_DATA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z22fpRm9rqlO"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "from sklearn.preprocessing import LabelBinarizer # Label encoding, 1-hot encoding, multi-encoding\n",
        "# LABEL binarizer is a 1-hot encoded MATRIX \n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import imutils\n",
        "from imutils import paths\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHCixC-TUt99",
        "outputId": "df43c278-dc6b-4ab1-bf96-9e984ed877f3"
      },
      "source": [
        "covid = '/content/SAMPLE'\n",
        "def loadImages(path = \"/content/SAMPLE\"):\n",
        "    temp = os.listdir(path)\n",
        "    images=[]\n",
        "    for i in temp:\n",
        "      if(i.endswith(\"jpg,png\")):\n",
        "        images.append(i)\n",
        "    print(temp)\n",
        "\n",
        "all_images = sorted(list(paths.list_images(covid)))\n",
        "all_images[:100000]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/SAMPLE/COVID 001.jpg',\n",
              " '/content/SAMPLE/COVID 002.jpg',\n",
              " '/content/SAMPLE/COVID 003.jpg',\n",
              " '/content/SAMPLE/COVID 004.jpg',\n",
              " '/content/SAMPLE/COVID 005.jpg',\n",
              " '/content/SAMPLE/COVID 006.jpg',\n",
              " '/content/SAMPLE/COVID 007.jpg',\n",
              " '/content/SAMPLE/COVID 008.jpg',\n",
              " '/content/SAMPLE/COVID 009.jpg',\n",
              " '/content/SAMPLE/COVID 010.jpg',\n",
              " '/content/SAMPLE/COVID 011.jpg',\n",
              " '/content/SAMPLE/COVID 012.jpg',\n",
              " '/content/SAMPLE/COVID 013.jpg',\n",
              " '/content/SAMPLE/COVID 014.jpg',\n",
              " '/content/SAMPLE/COVID 015.jpg',\n",
              " '/content/SAMPLE/COVID 016.jpg',\n",
              " '/content/SAMPLE/COVID 017.jpg',\n",
              " '/content/SAMPLE/COVID 018.jpg',\n",
              " '/content/SAMPLE/COVID 019.jpg',\n",
              " '/content/SAMPLE/COVID 020.jpg',\n",
              " '/content/SAMPLE/COVID 021.jpg',\n",
              " '/content/SAMPLE/COVID 022.jpg',\n",
              " '/content/SAMPLE/COVID 023.jpg',\n",
              " '/content/SAMPLE/COVID 024.jpg',\n",
              " '/content/SAMPLE/COVID 025.jpg',\n",
              " '/content/SAMPLE/COVID 026.jpg',\n",
              " '/content/SAMPLE/COVID 027.jpg',\n",
              " '/content/SAMPLE/COVID 028.jpg',\n",
              " '/content/SAMPLE/COVID 029.jpg',\n",
              " '/content/SAMPLE/COVID 030.jpg',\n",
              " '/content/SAMPLE/COVID 031.jpg',\n",
              " '/content/SAMPLE/COVID 032.jpg',\n",
              " '/content/SAMPLE/COVID 033.jpg',\n",
              " '/content/SAMPLE/COVID 034.jpg',\n",
              " '/content/SAMPLE/COVID 035.jpg',\n",
              " '/content/SAMPLE/COVID 036.jpg',\n",
              " '/content/SAMPLE/COVID 037.jpg',\n",
              " '/content/SAMPLE/COVID 038.jpg',\n",
              " '/content/SAMPLE/COVID 039.jpg',\n",
              " '/content/SAMPLE/COVID 040.jpg',\n",
              " '/content/SAMPLE/COVID 041.jpg',\n",
              " '/content/SAMPLE/COVID 042.jpg',\n",
              " '/content/SAMPLE/COVID 043.jpg',\n",
              " '/content/SAMPLE/COVID 044.jpg',\n",
              " '/content/SAMPLE/COVID 045.jpg',\n",
              " '/content/SAMPLE/COVID 046.jpg',\n",
              " '/content/SAMPLE/COVID 047.jpg',\n",
              " '/content/SAMPLE/COVID 048.jpg',\n",
              " '/content/SAMPLE/COVID 049.jpg',\n",
              " '/content/SAMPLE/COVID 050.jpg',\n",
              " '/content/SAMPLE/COVID 051.jpg',\n",
              " '/content/SAMPLE/COVID 052.jpg',\n",
              " '/content/SAMPLE/COVID 053.jpg',\n",
              " '/content/SAMPLE/COVID 054.jpg',\n",
              " '/content/SAMPLE/COVID 055.jpg',\n",
              " '/content/SAMPLE/COVID 056.jpg',\n",
              " '/content/SAMPLE/COVID 057.jpg',\n",
              " '/content/SAMPLE/COVID 058.jpg',\n",
              " '/content/SAMPLE/COVID 059.jpg',\n",
              " '/content/SAMPLE/COVID 060.jpg',\n",
              " '/content/SAMPLE/COVID 061.jpg',\n",
              " '/content/SAMPLE/COVID 062.jpg',\n",
              " '/content/SAMPLE/COVID 063.jpg',\n",
              " '/content/SAMPLE/COVID 064.jpg',\n",
              " '/content/SAMPLE/COVID 065.jpg',\n",
              " '/content/SAMPLE/COVID 066.jpg',\n",
              " '/content/SAMPLE/COVID 067.jpg',\n",
              " '/content/SAMPLE/COVID 068.jpg',\n",
              " '/content/SAMPLE/COVID 069.jpg',\n",
              " '/content/SAMPLE/COVID 070.jpg',\n",
              " '/content/SAMPLE/COVID 071.jpg',\n",
              " '/content/SAMPLE/COVID 072.jpg',\n",
              " '/content/SAMPLE/COVID 073.jpg',\n",
              " '/content/SAMPLE/COVID 074.jpg',\n",
              " '/content/SAMPLE/COVID 075.jpg',\n",
              " '/content/SAMPLE/COVID 076.jpg',\n",
              " '/content/SAMPLE/COVID 077.jpg',\n",
              " '/content/SAMPLE/COVID 078.jpg',\n",
              " '/content/SAMPLE/COVID 079.jpg',\n",
              " '/content/SAMPLE/COVID 080.jpg',\n",
              " '/content/SAMPLE/COVID 081.jpg',\n",
              " '/content/SAMPLE/COVID 082.jpg',\n",
              " '/content/SAMPLE/COVID 083.jpg',\n",
              " '/content/SAMPLE/COVID 084.jpg',\n",
              " '/content/SAMPLE/COVID 085.jpg',\n",
              " '/content/SAMPLE/COVID 086.jpg',\n",
              " '/content/SAMPLE/COVID 087.jpg',\n",
              " '/content/SAMPLE/COVID 088.jpg',\n",
              " '/content/SAMPLE/COVID 089.jpg',\n",
              " '/content/SAMPLE/COVID 090.jpg',\n",
              " '/content/SAMPLE/COVID 091.jpg',\n",
              " '/content/SAMPLE/COVID 092.jpg',\n",
              " '/content/SAMPLE/COVID 093.jpg',\n",
              " '/content/SAMPLE/COVID 094.jpg',\n",
              " '/content/SAMPLE/COVID 095.jpg',\n",
              " '/content/SAMPLE/COVID 096.jpg',\n",
              " '/content/SAMPLE/COVID 097.jpg',\n",
              " '/content/SAMPLE/COVID 098.jpg',\n",
              " '/content/SAMPLE/COVID 099.jpg',\n",
              " '/content/SAMPLE/COVID 100.jpg',\n",
              " '/content/SAMPLE/COVID 101.jpg',\n",
              " '/content/SAMPLE/COVID 102.jpg',\n",
              " '/content/SAMPLE/COVID 103.jpg',\n",
              " '/content/SAMPLE/COVID 104.jpg',\n",
              " '/content/SAMPLE/COVID 105.jpg']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ay_n8WDbFQSw"
      },
      "source": [
        "filenames=os.listdir(\"/content/SAMPLE\")\n",
        "categories=[]\n",
        "for f_name in filenames:\n",
        "    category=f_name.split(' ')[0]\n",
        "    \n",
        "    if category=='NORMAL':\n",
        "        categories.append(1)\n",
        "    else:\n",
        "        categories.append(0)\n",
        "df=pd.DataFrame({\n",
        "    'filename':filenames,\n",
        "    'category':categories\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gyxa5ADUFwpn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "96003a3b-c8c7-4b40-dd94-295fa53106d8"
      },
      "source": [
        "df\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>COVID 051.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>COVID 048.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>COVID 075.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>COVID 029.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>COVID 099.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>COVID 052.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>COVID 105.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>COVID 034.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>COVID 061.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>COVID 058.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>105 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          filename  category\n",
              "0    COVID 051.jpg         0\n",
              "1    COVID 048.jpg         0\n",
              "2    COVID 075.jpg         0\n",
              "3    COVID 029.jpg         0\n",
              "4    COVID 099.jpg         0\n",
              "..             ...       ...\n",
              "100  COVID 052.jpg         0\n",
              "101  COVID 105.jpg         0\n",
              "102  COVID 034.jpg         0\n",
              "103  COVID 061.jpg         0\n",
              "104  COVID 058.jpg         0\n",
              "\n",
              "[105 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOdx9cXKHs40"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0vXWsv9Dc3k"
      },
      "source": [
        "from keras import backend\n",
        "from keras.layers.core import Dense, Dropout, Flatten, Activation\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvNdsdsGMrEz"
      },
      "source": [
        "Image_Width=128\n",
        "Image_Height=128\n",
        "Image_Size=(Image_Width,Image_Height)\n",
        "Image_Channels=3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7p6ISMWuIMB3"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(Conv2D(32,(3,3),activation='relu',input_shape=(Image_Width,Image_Height,Image_Channels)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64,(3,3),activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(128,(3,3),activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512,activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "  optimizer='rmsprop',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhMDF1sHI_Lh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d951efed-4706-410d-dffb-40bb00e913ae"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 126, 126, 32)      896       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 126, 126, 32)      128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 63, 63, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 63, 63, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 61, 61, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 61, 61, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 30, 30, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 28, 28, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 28, 28, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               12845568  \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 12,942,786\n",
            "Trainable params: 12,941,314\n",
            "Non-trainable params: 1,472\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgF3VcPWI_I1"
      },
      "source": [
        "df[\"category\"] = df[\"category\"].replace({0:'COVID',1:'NORMAL'})\n",
        "train_df,validate_df = train_test_split(df,test_size=0.20,\n",
        "  random_state=42)\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "validate_df = validate_df.reset_index(drop=True)\n",
        "total_train=train_df.shape[0]\n",
        "total_validate=validate_df.shape[0]\n",
        "batch_size=15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYIgh005O-67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8378da6-1831-40db-ac51-c819c63090a4"
      },
      "source": [
        "total_validate"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBk2iYeCI_GR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b57d26db-9108-4c0c-8a80-f76955b9c63a"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rotation_range=15,\n",
        "                                rescale=1./255,\n",
        "                                shear_range=0.1,\n",
        "                                zoom_range=0.2,\n",
        "                                horizontal_flip=True,\n",
        "                                width_shift_range=0.1,\n",
        "                                height_shift_range=0.1\n",
        "                                )\n",
        "train_generator = train_datagen.flow_from_dataframe(train_df,\n",
        "                                                 \"/content/SAMPLE\",x_col='filename',y_col='category',\n",
        "                                                 target_size=Image_Size,\n",
        "                                                 class_mode='categorical',\n",
        "                                                 batch_size=batch_size)\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_generator = validation_datagen.flow_from_dataframe(\n",
        "    validate_df, \n",
        "    \"/content/SAMPLE\", \n",
        "    x_col='filename',\n",
        "    y_col='category',\n",
        "    target_size=Image_Size,\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size\n",
        ")\n",
        "test_datagen = ImageDataGenerator(rotation_range=15,\n",
        "                                rescale=1./255,\n",
        "                                shear_range=0.1,\n",
        "                                zoom_range=0.2,\n",
        "                                horizontal_flip=True,\n",
        "                                width_shift_range=0.1,\n",
        "                                height_shift_range=0.1)\n",
        "test_generator = train_datagen.flow_from_dataframe(train_df,\n",
        "                                                 \"/content/TEST-1\",x_col='filename',y_col='category',\n",
        "                                                 target_size=Image_Size,\n",
        "                                                 class_mode='categorical',\n",
        "                                                 batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 84 validated image filenames belonging to 1 classes.\n",
            "Found 21 validated image filenames belonging to 1 classes.\n",
            "Found 28 validated image filenames belonging to 1 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/dataframe_iterator.py:282: UserWarning: Found 56 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
            "  .format(n_invalid, x_col)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjXaSp18I_DY"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "earlystop = EarlyStopping(patience = 10)\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_acc',patience = 2,verbose = 1,factor = 0.5,min_lr = 0.00001)\n",
        "callbacks = [earlystop,learning_rate_reduction]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clS19OWxQA6h"
      },
      "source": [
        "test_filenames = os.listdir(\"/content/SAMPLE\")\n",
        "test_df = pd.DataFrame({\n",
        "    'filename': test_filenames\n",
        "})\n",
        "nb_samples = test_df.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjXpvJaDI-_e"
      },
      "source": [
        "epochs=10\n",
        "history = model.fit_generator(\n",
        "    train_generator, \n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=total_validate//batch_size,\n",
        "    steps_per_epoch=total_train//batch_size,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0AbUFcoQ_nu"
      },
      "source": [
        "test_filenames = os.listdir(\"/content/TEST-1\")\n",
        "test_df = pd.DataFrame({\n",
        "    'filename': test_filenames\n",
        "})\n",
        "nb_samples = test_df.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ-NwMosOFkl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f9c0b3a-7e55-463a-e72b-99bf64006262"
      },
      "source": [
        "predict = model.predict_generator(test_generator, steps=np.ceil(nb_samples/batch_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 6.0 batches). You may need to use the repeat() function when building your dataset.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBv4It8g3-kK",
        "outputId": "379674d6-6da0-410f-e6d4-53e79f8c407a"
      },
      "source": [
        "l=[]\n",
        "print(np.argmax(predict, axis=-1))\n",
        "l.extend(np.argmax(predict, axis=-1))\n",
        "print(l)\n",
        "len(l)\n",
        "k=np.zeros(49,dtype=int)\n",
        "l.extend(k)\n",
        "len(l)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "77"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUpuvrwn4f29"
      },
      "source": [
        "test_df[\"category\"]=l\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faZnQHzCOKZZ"
      },
      "source": [
        "test_df['category'] = l\n",
        "label_map = dict((v,k) for k,v in train_generator.class_indices.items())\n",
        "test_df['category'] = test_df['category'].replace(label_map)\n",
        "test_df['category'] = test_df['category'].replace({ 'NORMAL': 1, 'COVID': 0 })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1T9Zttvw43d3"
      },
      "source": [
        "test_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htjqG2cG47Bq"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "sample_test = test_df.head(18)\n",
        "sample_test.head()\n",
        "plt.figure(figsize=(12, 24))\n",
        "for index, row in sample_test.iterrows():\n",
        "    filename = row['filename']\n",
        "    category = row['category']\n",
        "    img = load_img(\"/content/TEST-1/\"+filename, target_size=Image_Size)\n",
        "    plt.subplot(6, 3, index+1)\n",
        "    plt.imshow(img)\n",
        "    plt.xlabel(filename + '(' + \"{}\".format(category) + ')' )\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqUHJUuu5F1X",
        "outputId": "11fb54dc-d310-4967-ef5f-786dd7bbb89e"
      },
      "source": [
        "results={\n",
        "    0:'COVID',\n",
        "    1:'NORMAL'\n",
        "}\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "im=Image.open(\"/content/download (2).jpeg\")\n",
        "im=im.resize(Image_Size)\n",
        "im=np.expand_dims(im,axis=0)\n",
        "im=np.array(im)\n",
        "im=im/255\n",
        "pred=model.predict_classes([im])[0]\n",
        "print(pred,results[pred])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 COVID\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tf_GSKvz6PPQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMl0HOjyJv8QnJX0bPHPeSr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaibram/Research/blob/main/Minor_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "YvaukVwR9kYZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "from sklearn.preprocessing import LabelBinarizer # Label encoding, 1-hot encoding, multi-encoding\n",
        "# LABEL binarizer is a 1-hot encoded MATRIX \n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import imutils\n",
        "from imutils import paths\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Image_Width=128\n",
        "Image_Height=128\n",
        "Image_Size=(Image_Width,Image_Height)\n",
        "Image_Channels=3"
      ],
      "metadata": {
        "id": "m6jvfhfY_m5W"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filenames=os.listdir(\"/content/sample_data/dogs-vs-cat-train\")\n",
        "categories=[]\n",
        "for f_name in filenames:\n",
        "    category=f_name.split('.')[0]\n",
        "    if category=='dog':\n",
        "        categories.append(1)\n",
        "    else:\n",
        "        categories.append(0)\n",
        "df=pd.DataFrame({\n",
        "    'filename':filenames,\n",
        "    'category':categories\n",
        "})"
      ],
      "metadata": {
        "id": "37nXzs_k_5c_"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D,\\\n",
        "     Dropout,Flatten,Dense,Activation,\\\n",
        "     BatchNormalization\n",
        "\n",
        "model=Sequential()\n",
        "\n",
        "model.add(Conv2D(32,(3,3),activation='relu',input_shape=(Image_Width,Image_Height,Image_Channels)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64,(3,3),activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128,(3,3),activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512,activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "  optimizer='rmsprop',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "jw09Z0vgACZI"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7QkIm6WAFtl",
        "outputId": "0e7f8b0c-01cb-4ba8-9ddd-0dcffc483b6f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 126, 126, 32)      896       \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 126, 126, 32)     128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 63, 63, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 63, 63, 32)        0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 61, 61, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 61, 61, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 30, 30, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 30, 30, 64)        0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 28, 28, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 28, 28, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 14, 14, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               12845568  \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 512)              2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 2)                 1026      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12,942,786\n",
            "Trainable params: 12,941,314\n",
            "Non-trainable params: 1,472\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "earlystop = EarlyStopping(patience = 10)\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_accuracy',patience = 2,verbose = 1,factor = 0.5,min_lr = 0.00001)\n",
        "callbacks = [earlystop,learning_rate_reduction]"
      ],
      "metadata": {
        "id": "p_0_SSVwAIm8"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"category\"] = df[\"category\"].replace({0:'cat',1:'dog'})\n",
        "train_df,validate_df = train_test_split(df,test_size=0.20,\n",
        "  random_state=42)\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "validate_df = validate_df.reset_index(drop=True)\n",
        "total_train=train_df.shape[0]\n",
        "total_validate=validate_df.shape[0]\n",
        "batch_size=15"
      ],
      "metadata": {
        "id": "Fsh04BkFAUPn"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rotation_range=15,\n",
        "                                rescale=1./255,\n",
        "                                shear_range=0.1,\n",
        "                                zoom_range=0.2,\n",
        "                                horizontal_flip=True,\n",
        "                                width_shift_range=0.1,\n",
        "                                height_shift_range=0.1\n",
        "                                )\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(train_df,\n",
        "                                                 \"/content/sample_data/dogs-vs-cat-train\",x_col='filename',y_col='category',\n",
        "                                                 target_size=Image_Size,\n",
        "                                                 class_mode='categorical',\n",
        "                                                 batch_size=batch_size)\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_generator = validation_datagen.flow_from_dataframe(\n",
        "    validate_df, \n",
        "    \"/content/sample_data/dogs-vs-cat-train\", \n",
        "    x_col='filename',\n",
        "    y_col='category',\n",
        "    target_size=Image_Size,\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rotation_range=15,\n",
        "                                rescale=1./255,\n",
        "                                shear_range=0.1,\n",
        "                                zoom_range=0.2,\n",
        "                                horizontal_flip=True,\n",
        "                                width_shift_range=0.1,\n",
        "                                height_shift_range=0.1)\n",
        "\n",
        "test_generator = train_datagen.flow_from_dataframe(train_df,\n",
        "                                                 \"/content/sample_data/dogs-vs-cat-test\",x_col='filename',y_col='category',\n",
        "                                                 target_size=Image_Size,\n",
        "                                                 class_mode='categorical',\n",
        "                                                 batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmCLFwayAXrz",
        "outputId": "ca831938-1227-4bde-df9c-3a10a817c644"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 719 validated image filenames belonging to 2 classes.\n",
            "Found 181 validated image filenames belonging to 2 classes.\n",
            "Found 0 validated image filenames belonging to 0 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py:991: UserWarning: Found 720 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
            "  n_invalid, x_col))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=10\n",
        "history = model.fit_generator(\n",
        "    train_generator, \n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=total_validate//batch_size,\n",
        "    steps_per_epoch=total_train//batch_size,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DL_G-sqAiCP",
        "outputId": "48364201-90e0-4547-adae-8c4aed727b64"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "48/48 [==============================] - 44s 888ms/step - loss: 1.4724 - accuracy: 0.5661 - val_loss: 0.6727 - val_accuracy: 0.5611 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "48/48 [==============================] - 42s 882ms/step - loss: 1.0973 - accuracy: 0.5994 - val_loss: 3.2299 - val_accuracy: 0.5556 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "48/48 [==============================] - ETA: 0s - loss: 1.0133 - accuracy: 0.5438\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "48/48 [==============================] - 44s 913ms/step - loss: 1.0133 - accuracy: 0.5438 - val_loss: 5.7752 - val_accuracy: 0.5556 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "48/48 [==============================] - 42s 882ms/step - loss: 0.9315 - accuracy: 0.5911 - val_loss: 0.8374 - val_accuracy: 0.5722 - lr: 5.0000e-04\n",
            "Epoch 5/10\n",
            "48/48 [==============================] - 42s 882ms/step - loss: 0.7955 - accuracy: 0.6161 - val_loss: 0.9447 - val_accuracy: 0.5833 - lr: 5.0000e-04\n",
            "Epoch 6/10\n",
            "48/48 [==============================] - 43s 906ms/step - loss: 0.8621 - accuracy: 0.6231 - val_loss: 1.0139 - val_accuracy: 0.5111 - lr: 5.0000e-04\n",
            "Epoch 7/10\n",
            "48/48 [==============================] - ETA: 0s - loss: 0.7765 - accuracy: 0.6481\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "48/48 [==============================] - 42s 871ms/step - loss: 0.7765 - accuracy: 0.6481 - val_loss: 1.2155 - val_accuracy: 0.5167 - lr: 5.0000e-04\n",
            "Epoch 8/10\n",
            "48/48 [==============================] - 42s 868ms/step - loss: 0.6935 - accuracy: 0.6718 - val_loss: 0.6116 - val_accuracy: 0.6778 - lr: 2.5000e-04\n",
            "Epoch 9/10\n",
            "48/48 [==============================] - 41s 863ms/step - loss: 0.6406 - accuracy: 0.6745 - val_loss: 0.5854 - val_accuracy: 0.6889 - lr: 2.5000e-04\n",
            "Epoch 10/10\n",
            "48/48 [==============================] - 43s 892ms/step - loss: 0.6482 - accuracy: 0.6926 - val_loss: 0.6439 - val_accuracy: 0.6611 - lr: 2.5000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"model1_catsVSdogs_10epoch.h5\")"
      ],
      "metadata": {
        "id": "t2Czt1O5Aoju"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_filenames = os.listdir(\"/content/sample_data/dogs-vs-cat-test\")\n",
        "test_df = pd.DataFrame({\n",
        "    'filename': test_filenames\n",
        "})\n",
        "nb_samples = test_df.shape[0]"
      ],
      "metadata": {
        "id": "vemO23VYAvnf"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict = model.predict(test_generator, steps=np.ceil(nb_samples/batch_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "ZqeAN39oA8sz",
        "outputId": "1e00f4f6-8745-47b5-cfdc-54f4b4abd5df"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-d81423e591a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_samples\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    100\u001b[0m       raise ValueError('Asked to retrieve element {idx}, '\n\u001b[1;32m    101\u001b[0m                        \u001b[0;34m'but the Sequence '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                        'has length {length}'.format(idx=idx, length=len(self)))\n\u001b[0m\u001b[1;32m    103\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_batches_seen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Asked to retrieve element 0, but the Sequence has length 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['category'] = np.argmax(predict, axis=-1)\n",
        "\n",
        "label_map = dict((v,k) for k,v in train_generator.class_indices.items())\n",
        "test_df['category'] = test_df['category'].replace(label_map)\n",
        "\n",
        "test_df['category'] = test_df['category'].replace({ 'dog': 1, 'cat': 0 })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "eLE1aa_DBBdH",
        "outputId": "f29dd8ce-3cba-454a-f2a7-29f1fece4f25"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-52414ee430a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlabel_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'predict' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "sample_test = test_df.head(18)\n",
        "sample_test.head()\n",
        "plt.figure(figsize=(12, 24))\n",
        "for index, row in sample_test.iterrows():\n",
        "    filename = row['filename']\n",
        "    category = row['category']\n",
        "    img = load_img(\"/content/sample_data/dogs-vs-cat-test\"+filename, target_size=Image_Size)\n",
        "    plt.subplot(6, 3, index+1)\n",
        "    plt.imshow(img)\n",
        "    plt.xlabel(filename + '(' + \"{}\".format(category) + ')' )\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SanUPT-_BIj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results={\n",
        "    0:'cat',\n",
        "    1:'dog'\n",
        "}\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "im=Image.open(\"/content/1-s2.0-S0735675720302746-gr1_lrg.jpg\")\n",
        "im=im.resize(Image_Size)\n",
        "im=np.expand_dims(im,axis=0)\n",
        "im=np.array(im)\n",
        "im=im/255\n",
        "pred=model.predict_classes([im])[0]\n",
        "print(pred,results[pred])"
      ],
      "metadata": {
        "id": "c3xwWuegBYMy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}